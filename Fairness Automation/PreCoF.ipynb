{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24b20fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb  7 13:44:34 2022\n",
    "\n",
    "@author: SGoethals\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from statistics import mean\n",
    "# nice.explainers import NICE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from statistics import median,mode\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "   \n",
    "def model(X, y, cat=None, to_drop=None):\n",
    "    if to_drop is not None:\n",
    "        X = X.drop(columns=to_drop)\n",
    "    \n",
    "    num = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num),\n",
    "            ('cate', categorical_transformer, cat)])\n",
    "\n",
    "    # Create the model pipeline\n",
    "    clf = Pipeline(steps=[('PP', preprocessor), \n",
    "                          ('RF', RandomForestClassifier(max_leaf_nodes=500, n_estimators=100))])\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    # Global accuracy\n",
    "    accuracyglobal = clf.score(X, y)\n",
    "    print(f'The accuracy of the model is {accuracyglobal}')\n",
    "    \n",
    "    # Get the feature names after the preprocessing pipeline\n",
    "    if cat != (None or []):\n",
    "        onehot_columns = clf.named_steps['PP'].named_transformers_['cate'].named_steps['onehot'].get_feature_names_out(input_features=cat)\n",
    "        feat_after_pipeline = np.array(num + list(onehot_columns))\n",
    "    \n",
    "    if cat == (None or []):\n",
    "        feat_after_pipeline = np.array(num)\n",
    "    \n",
    "    return clf, cat, num, feat_after_pipeline, feat_after_pipeline, accuracyglobal\n",
    "\n",
    "def calculate_fairness_metrics(X,y, value_combinations,clf,sensitive_attributes,good_outcome,bad_outcome,to_drop=None):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "    TP,FP,TN,FN,PPV,PR,TPR,FPR,accuracy,balanced_accuracy={},{},{},{},{},{},{},{},{},{}\n",
    "    if to_drop is not None:\n",
    "        X_testadapted = X_test.drop(columns=to_drop)\n",
    "    if to_drop is None:\n",
    "        X_testadapted=X_test\n",
    "    for attribute in value_combinations:\n",
    "        TP[tuple(attribute)], FP[tuple(attribute)], FN[tuple(attribute)],TN[tuple(attribute)]=0,0,0,0\n",
    "    for a in range(0,len(y_test)):\n",
    "        attribute=tuple(X_test.iloc[a][sensitive_attributes])\n",
    "        if clf.predict(X_testadapted.iloc[a:a+1,:])==good_outcome:\n",
    "            if y_test.iloc[a]==good_outcome:\n",
    "                TP[attribute]+=1\n",
    "            elif y_test.iloc[a]==bad_outcome:\n",
    "                FP[attribute]+=1\n",
    "        if clf.predict(X_testadapted.iloc[a:a+1,:])==bad_outcome:\n",
    "            if y_test.iloc[a]==bad_outcome:\n",
    "                TN[attribute]+=1\n",
    "            elif y_test.iloc[a]==good_outcome:\n",
    "                FN[attribute]+=1\n",
    "        #for attribute in value_combinations:\n",
    "        try: \n",
    "            PPV[attribute]=TP[attribute]/(TP[attribute]+FP[attribute]) #predictive parity\n",
    "            PR[attribute]=(TP[attribute]+FP[attribute])/(TP[attribute]+FP[attribute]+TN[attribute]+FN[attribute]) #demographic parity\n",
    "            TPR[attribute]=TP[attribute]/(TP[attribute]+FN[attribute])#equalized odds (and equal opportunity)\n",
    "            FPR[attribute]=FP[attribute]/(FP[attribute]+TN[attribute])#equalized odds\n",
    "            balanced_accuracy[attribute]=1/2*(TP[attribute])/(TP[attribute]+FN[attribute]) +1/2*(TN[attribute])/(TN[attribute]+FP[attribute])\n",
    "            accuracy[attribute]=(TP[attribute]+TN[attribute])/(TP[attribute]+FP[attribute]+TN[attribute]+FN[attribute]) \n",
    "        except ZeroDivisionError:\n",
    "            PPV[attribute], PR[attribute], TPR[attribute],FPR[attribute], balanced_accuracy[attribute], accuracy[attribute]=0,0,0,0,0,0\n",
    "    for attribute in value_combinations:\n",
    "        print(attribute)\n",
    "        print('The PPV of group:{} is {}'.format(attribute,PPV[attribute]))\n",
    "        print('The PR of group:{} is {}'.format(attribute,PR[attribute]))\n",
    "        print('The TPR of group:{} is {}'.format(attribute,TPR[attribute]))\n",
    "        print('The FPR of group:{} is {}'.format(attribute,FPR[attribute]))\n",
    "        print('The accuracy of group:{} is {}'.format(attribute,accuracy[attribute]))\n",
    "        print('The balanced_accuracy of group:{} is {}'.format(attribute,balanced_accuracy[attribute]))\n",
    "        print('The TP of group:{} is {}'.format(attribute,TP[attribute]))\n",
    "        print('The FP of group:{} is {}'.format(attribute,FP[attribute]))\n",
    "        print('The TN of group:{} is {}'.format(attribute,TN[attribute]))\n",
    "        print('The FN of group:{} is {}'.format(attribute,FN[attribute]))\n",
    "        print(' ')\n",
    "    return PPV,PR,TPR,FPR,TP,FP,TN,FN,accuracy,balanced_accuracy\n",
    "\n",
    "def calculate_default_2(X,y,num_feat,cat_feat,feature_names):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "    default_values={}\n",
    "    threshold=len(X_train)/100\n",
    "    for feature in feature_names:\n",
    "        feature_names=list(feature_names)\n",
    "        f=feature_names.index(feature)\n",
    "        default_values[feature]=[]\n",
    "        if f in num_feat:\n",
    "            default_values[feature]=np.percentile(X_train[feature],[10,20,3,40,50,60,70,80,90,100])\n",
    "            default_values[feature]=list(set( default_values[feature]))\n",
    "        if f in cat_feat:\n",
    "            valuessorted=X_train[feature].value_counts()\n",
    "            for i in range(0,len(valuessorted)):\n",
    "                value=valuessorted.index[i]\n",
    "                if valuessorted[value]>=threshold:\n",
    "                    default_values[feature].append(value)\n",
    "                else:\n",
    "                    break\n",
    "            if len(default_values[feature])>10:\n",
    "                default_values[feature]=valuessorted.index[0:10].tolist()\n",
    "            if len(default_values[feature])==0:\n",
    "                default_values[feature]=valuessorted.index[0:10].tolist()\n",
    "    return default_values\n",
    "\n",
    "\n",
    "\n",
    "def my_counterfactual(num_feat,cat_feat,X,y,value_combinations,sensitive_attributes,feature_names,clf,bad_outcome,good_outcome,default_values):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "    X_testadapted = X_test.drop(columns=sensitive_attributes)\n",
    "    dct,dct_with_value,factual,dct_multiple = {},{},{},{} #dct multiple for later\n",
    "    feature_names=list(feature_names)\n",
    "    for attribute in value_combinations:\n",
    "        dct[tuple(attribute)],dct_multiple[tuple(attribute)],dct_with_value[tuple(attribute)],factual[tuple(attribute)] = [],[],[],[]\n",
    "    for a in range(0,len(y_test)):\n",
    "        to_explain=X_testadapted.iloc[a:a+1,:]\n",
    "        if clf.predict(to_explain)[0]==bad_outcome:\n",
    "            attribute=tuple(X_test.iloc[a][sensitive_attributes])\n",
    "            cff=0\n",
    "            for feature in feature_names:\n",
    "                f=feature_names.index(feature)\n",
    "                tel=0\n",
    "                CF=copy.deepcopy(to_explain)\n",
    "                for i in range(0,len(default_values[feature])):\n",
    "                    CF[feature]=default_values[feature][i]\n",
    "                    if clf.predict(CF)[0]==good_outcome:\n",
    "                        tel+=1\n",
    "                        if f in cat_feat:\n",
    "                            dct_with_value[attribute].append(feature +':'+ str(default_values[feature][i]))\n",
    "                            factual[attribute].append(feature +':'+ str(to_explain[feature].item()))\n",
    "# to add: dct multiple\n",
    "                if tel>0:\n",
    "                    dct[attribute].append(feature)\n",
    "    return dct,dct_with_value,factual,dct_multiple\n",
    "\n",
    "\n",
    "def count_list(dct,TN,FN,TP,FP, value_combinations):\n",
    "     #attribute_values=X[sensitive_attribute].unique()\n",
    "     dct_sorted = {}\n",
    "     dct_count= {}\n",
    "     for attribute in value_combinations:\n",
    "         noemer=TN[attribute]+FN[attribute]\n",
    "         print('noemer is rejected')\n",
    "         #noemer=TN[attribute]+FN[attribute]+TP[attribute]+FP[attribute]\n",
    "         #print('noemer is amount of people in the test set')\n",
    "         a=Counter(dct[attribute])\n",
    "         aa = {k: v / noemer for k, v in a.items()}\n",
    "         dct_count[attribute]= aa\n",
    "         dct_sorted[attribute]= sorted(aa.items(), key=lambda x: x[1], reverse=True)\n",
    "     return dct_count,dct_sorted\n",
    "\n",
    "            \n",
    "def visualize_difference_2(dct_difference, feature_set, value_combinations, file,method,  cf_algo=None):\n",
    "    proxies={}\n",
    "    for attribute in value_combinations:\n",
    "        print(attribute)\n",
    "        #feature_list=[str(el) for el in feature_set]\n",
    "        Z=pd.DataFrame({'Name': list(feature_set), 'Difference': dct_difference[attribute]}).sort_values('Difference', ascending=False)\n",
    "        fig=plt.figure(figsize=(15, 5))\n",
    "        plt.rcParams['font.size']='30'\n",
    "        plt.barh(y='Name', width='Difference', data=Z[0:5],color='b')\n",
    "        plt.gca().invert_yaxis()\n",
    "        if cf_algo==None:\n",
    "            if method=='normal':\n",
    "                plt.xlabel(\"$PreCoF$\",fontsize=35)\n",
    "            if method=='cf':\n",
    "                plt.xlabel(\"$PreCoF_{c}$\",fontsize=35)\n",
    "            if method=='factual':\n",
    "                plt.xlabel(\"$PreCoF_{f}$\",fontsize=35)\n",
    "        if cf_algo=='NICE':\n",
    "            if method=='normal':\n",
    "                plt.xlabel(\"$NICE$\",fontsize=35)\n",
    "            if method=='cf':\n",
    "                plt.xlabel(\"$NICE_{c}$\",fontsize=35)\n",
    "            if method=='factual':\n",
    "                plt.xlabel(\"$NICE_{f}$\",fontsize=35)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(attribute)\n",
    "        proxies[attribute]=Z.iloc[0,0]\n",
    "        #plt.savefig(file, format = 'pdf', bbox_inches='tight')\n",
    "        file.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    return proxies\n",
    "        \n",
    "def calculate_difference_2 (dct_count,value_combinations):\n",
    "    dct_difference={}\n",
    "    feature_set=set()\n",
    "    for attribute in value_combinations:\n",
    "        feature_set.update(dct_count[attribute].keys())\n",
    "    for attribute in value_combinations:\n",
    "        dct_difference[attribute]=[]\n",
    "        #for feature in feature_names:\n",
    "        for feature in feature_set:\n",
    "            temp_list=[]\n",
    "            try:\n",
    "                dct_count[attribute][feature]\n",
    "            except KeyError:\n",
    "                dct_count[attribute][feature] = 0\n",
    "            for attribute2 in value_combinations:\n",
    "                try:\n",
    "                    dct_count[attribute2][feature]\n",
    "                except KeyError:\n",
    "                    dct_count[attribute2][feature]=0\n",
    "                if attribute!=attribute2:\n",
    "                    temp_list.append(dct_count[attribute2][feature])\n",
    "            dct_difference[attribute].append(dct_count[attribute][feature]-mean(temp_list))\n",
    "    return dct_difference, feature_set\n",
    "\n",
    "def feature_importances(clf,feat_after_pipeline,sensitive_attributes,file):\n",
    "    feat_values=clf['RF'].feature_importances_\n",
    "    #new_feat=clf['PP'].named_transformers_['cat']['onehot'].get_feature_names()\n",
    "    new_feat=feat_after_pipeline\n",
    "    # Zip coefficients and names together and make a DataFrame\n",
    "    zipped = zip(new_feat,feat_values)\n",
    "    dffeat = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "    # Sort the features by the absolute value of their coefficient\n",
    "    dffeat[\"abs_value\"] = dffeat[\"value\"].apply(lambda x: abs(x))\n",
    "    dffeat[\"colors\"] = dffeat[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "    dffeat = dffeat.sort_values(\"abs_value\", ascending=False)\n",
    "    import seaborn as sns\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "    sns.barplot(x=\"feature\",\n",
    "                y=\"value\",\n",
    "                data=dffeat.head(10),\n",
    "                palette='mako')\n",
    "               #palette=dffeat.head(20)[\"colors\"])\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "    ax.set_title(\"Top 10 Features\", fontsize=25)\n",
    "    plt.suptitle('sensitive attributes: {}'.format(sensitive_attributes),fontsize=20)\n",
    "    ax.set_ylabel(\"Feature importance\", fontsize=22)\n",
    "    ax.set_xlabel(\"Feature Name\", fontsize=22)\n",
    "    file.savefig(fig, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "#adapted for gerrymandering\n",
    "def calculate_explicit_bias(X,y,sensitive_attributes,clf,bad_outcome,good_outcome):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "    factual,explanation,sensitive_attributes_values=[],[],[]\n",
    "    for sensitive_attribute in sensitive_attributes:\n",
    "        sensitive_attributes_values.append(X_train[sensitive_attribute].unique())\n",
    "    sensitive_attributes_value_combinations=list(itertools.product(*sensitive_attributes_values))\n",
    "    for a in range(0,len(y_test)):\n",
    "        to_explain=X_test.iloc[a:a+1,:]    \n",
    "        if clf.predict(to_explain)[0] == bad_outcome:\n",
    "            CF=copy.deepcopy(to_explain)\n",
    "            for i in range(len(sensitive_attributes_value_combinations)):\n",
    "                CF[sensitive_attributes]=sensitive_attributes_value_combinations[i]\n",
    "                if clf.predict(CF)[0]==good_outcome:\n",
    "                    changes_factual=[]\n",
    "                    changes_explanation=[]\n",
    "                    for sensitive_attribute in sensitive_attributes:\n",
    "                        if X_test.iloc[a][sensitive_attribute]!= CF.iloc[0][sensitive_attribute]:\n",
    "                            factual_value=X_test.iloc[a][sensitive_attribute]\n",
    "                            explanation_value=CF.iloc[0][sensitive_attribute]\n",
    "                            changes_factual.append(X_test.iloc[a][sensitive_attribute])\n",
    "                            changes_explanation.append(CF.iloc[0][sensitive_attribute])\n",
    "                    factual.append(str(changes_factual))\n",
    "                    explanation.append(str(changes_explanation))\n",
    "    factual_dict=Counter(factual)\n",
    "    explanation_dict=Counter(explanation)\n",
    "    print('Explicit bias with our method. Factual: {}, Explanation {}'.format(factual_dict,explanation_dict))\n",
    "    return factual_dict,explanation_dict\n",
    "\n",
    "\n",
    "def visualize_explicit_bias(sensitive_attributes,factual, explanation,file,cf_algo=None):\n",
    "    fig = plt.figure()\n",
    "    plt.bar(factual.keys(), factual.values(), color='r', label = 'counterfactual values')\n",
    "    plt.title('Explicit bias: ' + str(\n",
    "        sensitive_attributes))\n",
    "    if cf_algo=='NICE':\n",
    "        plt.suptitle(\"NICE\",fontsize=15)\n",
    "    #plt.savefig(file, bbox_inches='tight')\n",
    "    plt.xticks(rotation=90)\n",
    "    file.savefig(fig)\n",
    "    fig = plt.figure()\n",
    "    plt.bar(explanation.keys(), explanation.values(), color='g', label='factual values')\n",
    "    plt.title('Explicit bias ' + str(\n",
    "        sensitive_attributes))\n",
    "    if cf_algo=='NICE':\n",
    "        plt.suptitle(\"NICE\",fontsize=15)\n",
    "   # plt.savefig(file, format = 'pdf', bbox_inches='tight')\n",
    "    plt.xticks(rotation=90)\n",
    "    file.savefig(fig, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "def visualize_fairness_metrics(accuracyglobal1,accuracyglobal2,accuracyglobal3, PR1,PR2,PR3, PPV1, PPV2, PPV3,TPR1,TPR2,TPR3,FPR1,FPR2,FPR3,accuracy1, accuracy2, accuracy3):\n",
    "    a1=max(PR1, key=PR1.get)\n",
    "    a2=min(PR1, key=PR1.get)\n",
    "    print('The unprotected group is {} and the protected group is {}'.format(a1,a2))\n",
    "    print('The accuracy of the model trained on the dataset with the sensitive attribuut is :{}'.format(accuracyglobal1))\n",
    "    print('The accuracy of the model trained on the dataset without the sensitive attribuut is :{}'.format(accuracyglobal2))\n",
    "    print('The accuracy of the model trained on the dataset without the sensitive attribuut and the proxy is is :{}'.format(accuracyglobal3))\n",
    "    print('The difference in positive rate for both sensitive groups: what is the difference in probability between the protected and unprotected group of being classified as positive?')\n",
    "    print('The demographic disparity of the model trained on the dataset with the sensitive attribuut is :{}. The predictive rates are: {},{}'.format(PR1[a1]-PR1[a2],PR1[a1],PR1[a2]))\n",
    "    print('The demographic disparity of the model trained on the dataset without the sensitive attribuut is :{}. The predictive rates are: {},{}'.format(PR2[a1]-PR2[a2],PR2[a1],PR2[a2]))\n",
    "    print('The demographic disparity of the model trained on the dataset without the sensitive attribuut and the proxy is :{}. The predictive rates are: {},{}'.format(PR3[a1]-PR3[a2],PR3[a1],PR3[a2]))\n",
    "    print('Predictive parity: if the protected and unprotected group have equal PPV: the probability of a subject with positive predicive value to truly belong to the positive class')\n",
    "    print(' The fraction of correct positive predictions should be the same for both groups')\n",
    "    print('The difference in predictive parity of the model trained on the dataset with the sensitive attribuut is :{}. The positive predicted values (PPV) are: {},{}'.format(PPV1[a1]-PPV1[a2],PPV1[a1], PPV1[a2]))\n",
    "    print('The difference in predictive parity of the model trained on the dataset without the sensitive attribuut is :{}. The positive predicted values (PPV) are: {},{}'.format(PPV2[a1]-PPV2[a2],PPV2[a1], PPV2[a2]))\n",
    "    print('The difference in predictive parity of the model trained on the dataset without the sensitive attribuut and the proxy is :{}. The positive predicted values (PPV) are: {},{}'.format(PPV3[a1]-PPV3[a2],PPV3[a1], PPV3[a2]))\n",
    "    print('Equal opportunity:Similar results for people with a good outcome of both groups')\n",
    "    print('The difference in equal opportunity in the model with the sensitive attribute is:{}'.format(TPR1[a1]-TPR1[a2]))\n",
    "    print('The difference in equal opportunity in the model without the sensitive attribute is:{}'.format(TPR2[a1]-TPR2[a2]))\n",
    "    print('The difference in equal opportunity in the model without the sensitive attribute and the proxy is:{}'.format(TPR3[a1]-TPR3[a2]))\n",
    "    print('The accuracy of the model in each group trained on the dataset with the sensitive attribuut is :{},{}'.format(accuracy1[a1],accuracy1[a2]))\n",
    "    print('The accuracy of the model in each group trained on the dataset without the sensitive attribuut is :{},{}'.format(accuracy2[a1],accuracy2[a2]))\n",
    "    print('The accuracy of the model in each group trained on the dataset without the sensitive attribuut and the proxy is is :{},{}'.format(accuracy3[a1], accuracy3[a2]))\n",
    "    \n",
    "#%%    \n",
    "def precof(X, y, sensitive_attributes, catws, good_outcome, bad_outcome, sensitive_value, file):\n",
    "    # Modelling with sensitive attribute\n",
    "    print('Modelling with sensitive attribute')\n",
    "    sensitive_attributes_values = []\n",
    "    for sensitive_attribute in sensitive_attributes:\n",
    "        sensitive_attributes_values.append(X[sensitive_attribute].unique())\n",
    "    \n",
    "    value_combinations = list(itertools.product(*sensitive_attributes_values))\n",
    "    print('Modelling with sensitive attribute')\n",
    "    \n",
    "    cat = catws.copy()\n",
    "    for attribute in sensitive_attributes:\n",
    "        if attribute in catws:\n",
    "            cat = cat.remove(attribute)\n",
    "    \n",
    "    clf, cat_feat, num_feat, feature_names, feat_after_pipeline, accuracyglobal1 = model(X, y, cat=catws, to_drop=None)\n",
    "    \n",
    "    feature_importances(clf, feat_after_pipeline, sensitive_attributes, file)\n",
    "    \n",
    "    PPV1, PR1, TPR1, FPR1, TP1, FP1, TN1, FN1, accuracy1, balanced_accuracy1 = calculate_fairness_metrics(X, y, value_combinations, clf, sensitive_attributes, good_outcome, bad_outcome, to_drop=None)\n",
    "    \n",
    "    print('Calculate explicit bias')\n",
    "    factual, explanation = calculate_explicit_bias(X, y, sensitive_attributes, clf, bad_outcome, good_outcome)\n",
    "    \n",
    "    visualize_explicit_bias(sensitive_attributes, factual, explanation, file)\n",
    "    \n",
    "    # Modelling without sensitive attribute\n",
    "    print('Modelling without sensitive attribute')\n",
    "    \n",
    "    # Ensure sensitive_attributes is a list of strings (not tuples)\n",
    "    clf, cat_feat, num_feat, feature_names, feat_after_pipeline, accuracyglobal2 = model(X, y, cat, to_drop=sensitive_attributes)\n",
    "    \n",
    "    feature_importances(clf, feat_after_pipeline, sensitive_attributes, file)\n",
    "    \n",
    "    PPV2, PR2, TPR2, FPR2, TP2, FP2, TN2, FN2, accuracy2, balanced_accuracy2 = calculate_fairness_metrics(X, y, value_combinations, clf, sensitive_attributes, good_outcome, bad_outcome, to_drop=sensitive_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f37aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pmlb import fetch_data\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, KBinsDiscretizer\n",
    "from aif360.sklearn.datasets import fetch_adult\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af74dd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling with sensitive attribute\n",
      "Modelling with sensitive attribute\n",
      "The accuracy of the model is 0.8796118095082102\n",
      "(1,)\n",
      "The PPV of group:(1,) is 0.7991735537190082\n",
      "The PR of group:(1,) is 0.24800163968026234\n",
      "The TPR of group:(1,) is 0.654041258031789\n",
      "The FPR of group:(1,) is 0.07146007940008822\n",
      "The accuracy of group:(1,) is 0.8453576552572248\n",
      "The balanced_accuracy of group:(1,) is 0.7912905893158504\n",
      "The TP of group:(1,) is 1934\n",
      "The FP of group:(1,) is 486\n",
      "The TN of group:(1,) is 6315\n",
      "The FN of group:(1,) is 1023\n",
      " \n",
      "(0,)\n",
      "The PPV of group:(0,) is 0.8712328767123287\n",
      "The PR of group:(0,) is 0.0745658835546476\n",
      "The TPR of group:(0,) is 0.5792349726775956\n",
      "The FPR of group:(0,) is 0.010814542107685227\n",
      "The accuracy of group:(0,) is 0.9432073544433095\n",
      "The balanced_accuracy of group:(0,) is 0.7842102152849553\n",
      "The TP of group:(0,) is 318\n",
      "The FP of group:(0,) is 47\n",
      "The TN of group:(0,) is 4299\n",
      "The FN of group:(0,) is 231\n",
      " \n",
      "Calculate explicit bias\n",
      "Explicit bias with our method. Factual: Counter({'[0.0]': 6}), Explanation Counter({'[1.0]': 6})\n",
      "Modelling without sensitive attribute\n",
      "The accuracy of the model is 0.8800212931493386\n",
      "(1,)\n",
      "The PPV of group:(1,) is 0.8018166804293972\n",
      "The PR of group:(1,) is 0.24820659971305595\n",
      "The TPR of group:(1,) is 0.6567467027392627\n",
      "The FPR of group:(1,) is 0.070577856197618\n",
      "The accuracy of group:(1,) is 0.8467923754867801\n",
      "The balanced_accuracy of group:(1,) is 0.7930844232708223\n",
      "The TP of group:(1,) is 1942\n",
      "The FP of group:(1,) is 480\n",
      "The TN of group:(1,) is 6321\n",
      "The FN of group:(1,) is 1015\n",
      " \n",
      "(0,)\n",
      "The PPV of group:(0,) is 0.8657534246575342\n",
      "The PR of group:(0,) is 0.0745658835546476\n",
      "The TPR of group:(0,) is 0.575591985428051\n",
      "The FPR of group:(0,) is 0.011274735388863323\n",
      "The accuracy of group:(0,) is 0.9423901940755873\n",
      "The balanced_accuracy of group:(0,) is 0.7821586250195938\n",
      "The TP of group:(0,) is 316\n",
      "The FP of group:(0,) is 49\n",
      "The TN of group:(0,) is 4297\n",
      "The FN of group:(0,) is 233\n",
      " \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pmlb import fetch_data\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Fetch the adult dataset\n",
    "adult = fetch_data('adult')\n",
    "X = adult.drop(columns=['target', 'fnlwgt', 'native-country'])\n",
    "y = adult['target']\n",
    "\n",
    "# Update sensitive attributes to be a list\n",
    "sensitive_attributes = ['sex']  # Pass as a list\n",
    "\n",
    "# Define other parameters\n",
    "good_outcome = 0\n",
    "bad_outcome = 1\n",
    "cat = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "filename = 'adult_images.pdf'  \n",
    "file = PdfPages(filename)\n",
    "\n",
    "# Call the precof function\n",
    "precof(X, y, sensitive_attributes, cat, good_outcome, bad_outcome, sensitive_value=0, file=file)\n",
    "\n",
    "# Close the PDF file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "912dc14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lv/29s7r4k5433dywy1_wbq0m080000gn/T/ipykernel_8940/933536974.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['African_American'] = (compas['race'] == 'African-American')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling with sensitive attribute\n",
      "Modelling with sensitive attribute\n",
      "The accuracy of the model is 0.798645992574798\n",
      "(False,)\n",
      "The PPV of group:(False,) is 0.797829811536265\n",
      "The PR of group:(False,) is 0.6967767608436132\n",
      "The TPR of group:(False,) is 0.9024547803617571\n",
      "The FPR of group:(False,) is 0.36683937823834195\n",
      "The accuracy of group:(False,) is 0.7990449661758854\n",
      "The balanced_accuracy of group:(False,) is 0.7678077010617075\n",
      "The TP of group:(False,) is 1397\n",
      "The FP of group:(False,) is 354\n",
      "The TN of group:(False,) is 611\n",
      "The FN of group:(False,) is 151\n",
      " \n",
      "(True,)\n",
      "The PPV of group:(True,) is 0.8008504606661941\n",
      "The PR of group:(True,) is 0.47317236753856473\n",
      "The TPR of group:(True,) is 0.7946554149085795\n",
      "The FPR of group:(True,) is 0.18012820512820513\n",
      "The accuracy of group:(True,) is 0.8078470824949698\n",
      "The balanced_accuracy of group:(True,) is 0.8072636048901871\n",
      "The TP of group:(True,) is 1130\n",
      "The FP of group:(True,) is 281\n",
      "The TN of group:(True,) is 1279\n",
      "The FN of group:(True,) is 292\n",
      " \n",
      "Calculate explicit bias\n",
      "Explicit bias with our method. Factual: Counter(), Explanation Counter()\n",
      "Modelling without sensitive attribute\n",
      "The accuracy of the model is 0.7984822013540074\n",
      "(False,)\n",
      "The PPV of group:(False,) is 0.8037865748709122\n",
      "The PR of group:(False,) is 0.6935933147632312\n",
      "The TPR of group:(False,) is 0.9050387596899225\n",
      "The FPR of group:(False,) is 0.3544041450777202\n",
      "The accuracy of group:(False,) is 0.8054118583366494\n",
      "The balanced_accuracy of group:(False,) is 0.7753173073061012\n",
      "The TP of group:(False,) is 1401\n",
      "The FP of group:(False,) is 342\n",
      "The TN of group:(False,) is 623\n",
      "The FN of group:(False,) is 147\n",
      " \n",
      "(True,)\n",
      "The PPV of group:(True,) is 0.8020158387329014\n",
      "The PR of group:(True,) is 0.46579476861167\n",
      "The TPR of group:(True,) is 0.7834036568213784\n",
      "The FPR of group:(True,) is 0.1762820512820513\n",
      "The accuracy of group:(True,) is 0.8044936284372904\n",
      "The balanced_accuracy of group:(True,) is 0.8035608027696635\n",
      "The TP of group:(True,) is 1114\n",
      "The FP of group:(True,) is 275\n",
      "The TN of group:(True,) is 1285\n",
      "The FN of group:(True,) is 308\n",
      " \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Load the COMPAS dataset\n",
    "compas = pd.read_csv('cox-violent-parsed.csv')\n",
    "\n",
    "# Select the relevant features (dropping the 'race' column, and adding 'African_American' column)\n",
    "X = compas[['sex', 'age', 'age_cat', 'juv_fel_count', 'decile_score', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_desc']]\n",
    "\n",
    "# Create the target variable (replace -1 with 0)\n",
    "y = compas['is_recid'].replace(to_replace=-1, value=0)\n",
    "\n",
    "# Create a binary column 'African_American' based on 'race' being 'African-American'\n",
    "X['African_American'] = (compas['race'] == 'African-American')\n",
    "\n",
    "# # Drop the 'race' column as it is already encoded into 'African_American'\n",
    "# X = X.drop('race', axis=1)\n",
    "\n",
    "# Define sensitive attribute and categorical features\n",
    "sensitive_attribute = ['African_American']  # Make it a list\n",
    "sensitive_value = True  # Indicates the value of the sensitive attribute we care about\n",
    "good_outcome = 0  # No recidivism\n",
    "bad_outcome = 1   # Recidivism\n",
    "\n",
    "# List of categorical features\n",
    "cat = ['age_cat', 'sex', 'c_charge_desc']\n",
    "\n",
    "# Define the filename for saving the results\n",
    "filename = 'compas_images.pdf'\n",
    "file = PdfPages(filename)\n",
    "\n",
    "# Call the PRECOF function\n",
    "precof(X, y, sensitive_attributes=sensitive_attribute, catws=cat, good_outcome=good_outcome, bad_outcome=bad_outcome, sensitive_value=sensitive_value, file=file)\n",
    "\n",
    "# Close the PDF file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387dfde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
